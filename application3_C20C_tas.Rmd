---
title: Application 3: trends in seasonal maximum temperature
author: Mark Risser
date: 2 April 2019
output: html_document
---

\   

```{r, message = FALSE, warning = FALSE}
library(nimble)
library(coda)
library(StatMatch)
nimbleOptions(verbose = TRUE)
source("../BayesNSGP/BayesNSGP/R/core.R")
source("../BayesNSGP/BayesNSGP/R/NNGP.R")
source("../BayesNSGP/BayesNSGP/R/SGV.R")

library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(viridis)

```

\   


### Introduction

Finally, we attempt to analyze a much larger data set using the output of an ensemble of climate model simulations from the C20C+ Detection and Attribution Project. [Insert details on C20C+.] The large ensemble of relative high-resolution simulations is explicitly designed to characterize extremes. The model is defined on a $288 \times 192$ global grid with $55,296$ grid cells.

In this analysis, we will analyze trends in seasonal maximum temperature over 1959-2015. Using the 50-member ensemble of simulations over this time, for each ensemble member we first calculate the Boreal winter (December, January, February) average temperature for each year and for each grid cell. Then, aggregating over all 50 ensemble members, we extract the maximum seasonal average temperature and calculate the linear trend in the maximum seasonal average temperature.

The size of this data set makes it essentially impossible to analyze using a full Gaussian process. However, inference is possible using the approximate GP methods. Here, we apply the NNGP to this data set.

First, load the data to be used in both analyses and create the constants needed for the NIMBLE functionality:

```{r, message = FALSE}
# Load data =====================================
tasMax_trendDF <- read.csv("data/C20C_DJFtasMax_trend.csv")
coords <- as.matrix(tasMax_trendDF[,c("longitude", "latitude")])
z <- tasMax_trendDF$trendMax
Xmat <- unname(lm(trendMax ~ latitude*ind_land, x = TRUE, 
                  data = tasMax_trendDF)$x)
N <- nrow(tasMax_trendDF)

# MCMC setup ====================================
niter <- 2000
strt.kp <- 1001
```

Take a quick look at the trends:

```{r, echo = FALSE, fig.height=4, fig.width=7, warning = FALSE}
ggplot(tasMax_trendDF, aes(x = longitude, y = latitude, fill = trendMax)) +
  geom_tile() + coord_fixed(ratio = 1) +
  geom_polygon( data = map_data("world"), aes(x = long, y = lat, group = group),
                color = "black", fill = NA, size = 0.2) + 
  scale_fill_gradientn(colors = brewer.pal(9, "RdBu")[9:1], limits = c(-8,8)) +
  ggtitle("Trend in maximum DJF temperature, 1960-2015 (K/ha)")
```

For a global data set, it is important to allow the properties of the covariance function to vary over space. Looking at the data, it appears as though there is a relationship between latitude and the trend, potentially interacting with a ocean vs. land effect. So, we will allow each of the mean, nugget variance, and spatial variance to vary linearly with latitude, with an interaction term that indicates whether the grid cell is over land or ocean (a grid cell is determined to be over land if at least 95\% of the grid cell is on land). Since the covariance function used here is not valid on the sphere, we instead represent the longitude/latitude coordinates as points in a 3-dimensional space and therefore must use the locally isotropic version of the covariance function. We model the locally isotropic range using an approximate Gaussian process defined on a coarse 8 $\times$ 16 grid over the globe.

#### (1) NNGP likelihood

```{r}
# R^3 coordinates
xyz.crds <- matrix(NA,nrow(coords),3)
# Transform degrees to radians
lat.radians <- coords[,2]*(pi/180)
lon.radians <- coords[,1]*(pi/180)
for(i in 1:nrow(coords)){
  xyz.crds[i,1] <- 6371*cos(lat.radians[i])*cos(lon.radians[i])
  xyz.crds[i,2] <- 6371*cos(lat.radians[i])*sin(lon.radians[i])
  xyz.crds[i,3] <- 6371*sin(lat.radians[i])
}

# Set up the knot locations
x_min <- min(coords[,1])
x_max <- max(coords[,1])
y_min <- min(coords[,2])
y_max <- max(coords[,2])
knot_lonlat <- expand.grid(
  lon = seq(from = x_min + 0.5*(x_max - x_min)/16, 
            to = x_max - 0.5*(x_max - x_min)/16, 
            length = 16),
  lat = seq(from = y_min + 0.5*(y_max - y_min)/8, 
            to = y_max - 0.5*(y_max - y_min)/8, 
            length = 8)
)
dist_coords <- as.matrix(dist(coords, upper = T, diag = T))
Sigma_knot_dist <- as.matrix(dist(knot_coords, upper = T, diag = T))
Sigma_cross_dist <- mahalanobis.dist(coords, knot_coords, diag(2))


# NNGP
nID_NNGP <- determineNeighbors(xyz.crds, k)
dist_NNGP <- nsDist3d(locs, nID_NNGP, isotropic = TRUE)
constants_NNGP <- list( dist1_3d = dist_NNGP$dist1_3d, dist2_3d = dist_NNGP$dist2_3d, 
                        dist12_3d = dist_NNGP$dist12_3d, nu = 0.5, N = N, k = k, nID = nID_NNGP, 
                        Sigma_HP1 = 2, d = 3 )



# Distance matrices and constants
dist_mats <- nsDist(coords)
constants <- list( 
  dist1_sq = dist_mats$dist1_sq, dist2_sq = dist_mats$dist2_sq, 
  dist12 = dist_mats$dist12, nu = 0.5, N = N,
  tau_HP1 = 10, p_tau = ncol(Xmat), X_tau = Xmat,
  sigma_HP1 = 10, p_sigma = ncol(Xmat), X_sigma = Xmat,
  Sigma_HP1 = 5, p_Sigma = ncol(Xmat), X_Sigma = Xmat,
  mu_HP1 = 10, p_mu = ncol(Xmat), X_mu = Xmat )

# Setup
Rmodel_fullGP <- nsgpModel( likelihood = "fullGP", constants = constants, z = z,
                            tau_model = "logLinReg", sigma_model = "logLinReg", 
                            mu_model = "linReg", Sigma_model = "compReg" )
compl_model_fullGP <- compileNimble( Rmodel_fullGP )
conf_model_fullGP <- configureMCMC( Rmodel_fullGP )
conf_model_fullGP$removeSamplers()
conf_model_fullGP$addSampler(target = c("alpha[1]","alpha[2]","alpha[3]","alpha[4]"), type = "RW_block")
conf_model_fullGP$addSampler(target = c("delta[1]","delta[2]","delta[3]","delta[4]"), type = "RW_block")
conf_model_fullGP$addSampler(target = c("beta[1]","beta[2]","beta[3]","beta[4]"), type = "RW_block")
conf_model_fullGP$addSampler(target = c("Sigma_coef1[1]","Sigma_coef1[2]","Sigma_coef1[3]","Sigma_coef1[4]"), 
                             type = "RW_block")
conf_model_fullGP$addSampler(target = c("Sigma_coef2[1]","Sigma_coef2[2]","Sigma_coef2[3]","Sigma_coef2[4]"), 
                             type = "RW_block")
conf_model_fullGP$addSampler(target = c("Sigma_coef3[1]","Sigma_coef3[2]","Sigma_coef3[3]","Sigma_coef3[4]"), 
                             type = "RW_block")
conf_model_fullGP$getSamplers()
nim_mcmc_fullGP <- buildMCMC(conf_model_fullGP)
nim_Cmcmc_fullGP <- compileNimble(nim_mcmc_fullGP, project = Rmodel_fullGP)

# Run MCMC
prt <- proc.time()
nim_Cmcmc_fullGP$run(niter)
fullGP.tm <- proc.time() - prt
postSamp_fullGP <- as.matrix(nim_Cmcmc_fullGP$mvSamples)[strt.kp:niter,]

```

#### (2) NNGP likelihood

```{r}
# Distance matrices and constants
k <- 15
nID_NNGP <- determineNeighbors(coords, k)
dist_NNGP <- nsDist3d(coords, nID_NNGP)
constants_NNGP <- list( 
  dist1_3d = dist_NNGP$dist1_3d, dist2_3d = dist_NNGP$dist2_3d, 
  dist12_3d = dist_NNGP$dist12_3d, nu = 0.5, N = N, k = k, nID = nID_NNGP,
  tau_HP1 = 10, p_tau = ncol(Xmat), X_tau = Xmat,
  sigma_HP1 = 10, p_sigma = ncol(Xmat), X_sigma = Xmat,
  Sigma_HP1 = 5, p_Sigma = ncol(Xmat), X_Sigma = Xmat,
  mu_HP1 = 10, p_mu = ncol(Xmat), X_mu = Xmat )

# Setup
Rmodel_NNGP <- nsgpModel( likelihood = "NNGP", constants = constants_NNGP, z = z,
                          tau_model = "logLinReg", sigma_model = "logLinReg", 
                          mu_model = "linReg", Sigma_model = "compReg" )
compl_model_NNGP <- compileNimble( Rmodel_NNGP )
conf_model_NNGP <- configureMCMC( Rmodel_NNGP )
conf_model_NNGP$removeSamplers()
conf_model_NNGP$addSampler(target = c("alpha[1]","alpha[3]",
                                      "Sigma_coef1[1]","Sigma_coef1[3]",
                                      "Sigma_coef2[1]","Sigma_coef2[3]",
                                      "Sigma_coef3[1]","Sigma_coef3[3]"), type = "RW_block")
conf_model_NNGP$addSampler(target = c("alpha[2]","alpha[4]",
                                      "Sigma_coef1[2]","Sigma_coef1[4]",
                                      "Sigma_coef2[2]","Sigma_coef2[4]",
                                      "Sigma_coef3[2]","Sigma_coef3[4]"),
                           type = "RW_block")
# conf_model_NNGP$addSampler(target = c("alpha[1]","alpha[2]","alpha[3]","alpha[4]"), type = "RW_block")
conf_model_NNGP$addSampler(target = c("delta[1]","delta[2]","delta[3]","delta[4]"), type = "RW_block")
# conf_model_NNGP$addSampler(target = c("beta[1]","beta[2]","beta[3]","beta[4]"), type = "RW_block")
# conf_model_NNGP$addSampler(target = c("Sigma_coef1[1]","Sigma_coef1[2]","Sigma_coef1[3]","Sigma_coef1[4]"), 
#                              type = "RW_block")
# conf_model_NNGP$addSampler(target = c("Sigma_coef2[1]","Sigma_coef2[2]","Sigma_coef2[3]","Sigma_coef2[4]"), 
#                              type = "RW_block")
# conf_model_NNGP$addSampler(target = c("Sigma_coef3[1]","Sigma_coef3[2]","Sigma_coef3[3]","Sigma_coef3[4]"), 
#                              type = "RW_block")
# conf_model_NNGP$addSampler(target = c("alpha[1]","alpha[2]","alpha[3]","alpha[4]",
#                                       "delta[1]","delta[2]","delta[3]","delta[4]",
#                                       "Sigma_coef1[1]","Sigma_coef1[2]","Sigma_coef1[3]","Sigma_coef1[4]",
#                                       "Sigma_coef2[1]","Sigma_coef2[2]","Sigma_coef2[3]","Sigma_coef2[4]",
#                                       "Sigma_coef3[1]","Sigma_coef3[2]","Sigma_coef3[3]","Sigma_coef3[4]"), 
#                              type = "RW_block")
conf_model_NNGP$addSampler(target = c("beta[1]","beta[2]","beta[3]","beta[4]"), type = "RW_block")
conf_model_NNGP$getSamplers()
nim_mcmc_NNGP <- buildMCMC(conf_model_NNGP)
nim_Cmcmc_NNGP <- compileNimble(nim_mcmc_NNGP, project = Rmodel_NNGP)

prt <- proc.time()
nim_Cmcmc_NNGP$run(10000)
NNGP.tm <- proc.time() - prt
postSamp_NNGP <- as.matrix(nim_Cmcmc_NNGP$mvSamples)





postSamp_NNGP_orig <- postSamp_NNGP
par(ask=T)
for(t in 1:ncol(postSamp_NNGP)){
  plot(postSamp_NNGP[,t], type = "l", main = colnames(postSamp_NNGP)[t])
}




```



